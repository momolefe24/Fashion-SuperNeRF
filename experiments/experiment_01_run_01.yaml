---
# ------------------- Experiment Facts
experiment_facts:
 experiment_number: 1
 type: "NeRF" # [ESRGAN, NeRF, Viton, FashionNeRF]
 root_path: "./"
 run_number: 1
 experiment_name: "Neural Radiance Field For Eric"
 experiment_description: "Perform NeRF on Eric, eval pretrained SR for HR-VITON"
 cuda: True


# ------------------- Checkpoint Facts
checkpoint_facts:
 load_checkpoint: False
 save_checkpoint: True
 root_path: "Checkpoints"
 NeRF:
  checkpoint_nerf: "NeRF.pth"
 ESRGAN:
  checkpoint_gen: "esrgan_gen.pth"
  checkpoint_disc: "esrgan_disc.pth"
 VITON:
  checkpoint_seg: "seg_final.pth"
  checkpoint_gmm: "gmm_final.pth"
  checkpoint_alias: "alias_final.pth"
  checkpoint_model: "viton.pth"



# ------------------- Result Facts
results_facts:
 experiment_number: 1
 run_number: 1
 root_path: "Results"
 basedir: "./logs"
 training_evaluation:
  training_loss: ""
  training_images: ""

# ------------------- Summary Facts
summary_facts:
  root_path: "Summary"
  ESRGAN:
   ground_truth: "ground_truth"
   sr: "sr"


# ------------------- Dataset Facts
dataset_facts:
 model: "eric"
 dataset_type: "blender"
 image:
  channels: 3
  lr_shape: (3,100,100)
  hr_shape: (3,1024,768)
 root_path: "Dataset"
 script_path: "dataset.py"
 transforms:
  mean:
   - 0.485
   - 0.456
   - 0.406
  std:
   - 0.229
   - 0.224
   - 0.225


# ------------------- Model Facts
model_facts:
 script_path:
  NeRF: "NeRF/model.py"
  SR: "ESRGAN/model.py"
  VITON: "VITON/model.py"
 in_channels: 3

# ------------------- Training Facts
training_facts:
 script_path: "train.py"
 batch_size: 2
 num_workers: 1
 NeRF:
  epochs: 5000
  no_batching: True
  use_viewdirs: True
  white_bkgd: False
  lrate_decay: 500
  N_samples: 64
  N_importance: 128
  N_rand: 1024
  precrop_iters: 500
  precrop_frec: 0.5
  half_res: False
 ESRGAN:
  epochs: 2000
  filters: 64
  num_res_blocks: 8
  upscale_factor: 10
  leaky_relu: 0.2
  features: [64, 64, 128, 128, 256,256, 512, 512, 1024, 1024]
  adaptive_average_pool: (12, 12)
  initialized_weight_scale: 0.1
  residual_in_residual_dense_block: 0.2
  lambda_gp: 10
  lambda_adv: 5e-3 # adversarial loss weight"
  lambda_pixel: 1e-2 # pixel-wise loss weight
  interpolation_mode: "nearest"
  learning_rate: 0.0002 # Adam
  beta1: 0.9
  beta2: 0.999
  decay_epoch: 100
 VITON:
  epochs: 2000
  display_freq: 1
  semantic_nc: 13 # Number of parsing map classes
  init_type: "xavier"
  init_variance: 0.02 # Variance of the initialization distribution
  grid_size: 5 # For GMM
  alias_generator:
   norm_G: "spectralaliasinstance"
   ngf: 64 # Number of generator filters in the first conv layer
   num_upsampling_layers: "most"
  learning_rate: 1.0e-5
